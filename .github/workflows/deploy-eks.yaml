name: Deploy EKS with Validation and Cleanup

on:
  workflow_dispatch:
    inputs:
      name:
        description: "EKS cluster name"
        required: true
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      destroy_on_failure:
        description: 'Destroy resources if deployment fails'
        required: false
        default: true
        type: boolean

env:
  TF_VERSION: 1.9.0
  KUBECTL_VERSION: 1.28.0

jobs:
  validate:
    name: 🔍 Validate Configuration
    environment: ${{ github.event.inputs.environment }}
    runs-on: ubuntu-latest
    outputs:
      cluster_name: ${{ steps.validate.outputs.cluster_name }}
      environment: ${{ steps.validate.outputs.environment }}
      
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Validate inputs
        id: validate
        run: |
          # Validate cluster name
          if [[ ! "${{ github.event.inputs.name }}" =~ ^[a-zA-Z][a-zA-Z0-9-]*[a-zA-Z0-9]$ ]]; then
            echo "❌ Invalid cluster name. Must start with letter, end with alphanumeric, and contain only letters, numbers, and hyphens."
            exit 1
          fi
          
          # Check name length
          if [ ${#cluster_name} -gt 100 ]; then
            echo "❌ Cluster name too long (max 100 characters)"
            exit 1
          fi
          
          echo "✅ Cluster name validation passed"
          echo "cluster_name=${{ github.event.inputs.name }}" >> $GITHUB_OUTPUT
          echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ vars.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Check AWS connectivity
        run: |
          echo "🔗 Testing AWS connectivity..."
          aws sts get-caller-identity
          echo "✅ AWS connectivity verified"

      - name: Check if cluster already exists
        id: cluster_check
        run: |
          echo "🔍 Checking if cluster '${{ github.event.inputs.name }}' already exists..."
          if aws eks describe-cluster --name "${{ github.event.inputs.name }}" --region "${{ vars.AWS_REGION }}" 2>/dev/null; then
            echo "⚠️ Cluster '${{ github.event.inputs.name }}' already exists!"
            echo "cluster_exists=true" >> $GITHUB_OUTPUT
          else
            echo "✅ Cluster name is available"
            echo "cluster_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Format Check
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          echo "🎨 Checking Terraform formatting..."
          terraform fmt -check
          echo "✅ Terraform format check passed"

      - name: Terraform Init
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          echo "🚀 Initializing Terraform..."
          terraform init \
            -backend-config="bucket=${{ vars.TF_STATE_BUCKET }}" \
            -backend-config="key=eks/${{ github.event.inputs.environment }}/${{ github.event.inputs.name }}/terraform.tfstate" \
            -backend-config="region=${{ vars.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ vars.TF_STATE_LOCK_TABLE }}" \
            -backend-config="encrypt=true"

      - name: Terraform Validate
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          echo "✅ Validating Terraform configuration..."
          terraform validate
          echo "✅ Terraform validation passed"

  plan:
    name: 📋 Plan Infrastructure
    needs: validate
    environment: ${{ github.event.inputs.environment }}
    runs-on: ubuntu-latest
    outputs:
      plan_exitcode: ${{ steps.plan.outputs.exitcode }}
      
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ vars.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TF_STATE_BUCKET }}" \
            -backend-config="key=eks/${{ github.event.inputs.environment }}/${{ github.event.inputs.name }}/terraform.tfstate" \
            -backend-config="region=${{ vars.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ vars.TF_STATE_LOCK_TABLE }}" \
            -backend-config="encrypt=true"

      - name: Terraform Plan
        id: plan
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        env:
          TF_VAR_cluster_name: ${{ github.event.inputs.name }}
          TF_VAR_environment: ${{ github.event.inputs.environment }}
        run: |
          echo "📋 Creating Terraform plan..."
          terraform plan \
            -var-file="terraform.tfvars" \
            -out=tfplan \
            -detailed-exitcode \
            -no-color
          
          exitcode=$?
          echo "exitcode=$exitcode" >> $GITHUB_OUTPUT
          
          if [ $exitcode -eq 1 ]; then
            echo "❌ Terraform plan failed"
            exit 1
          elif [ $exitcode -eq 2 ]; then
            echo "📝 Changes detected in plan"
          else
            echo "✅ No changes needed"
          fi

      - name: Upload Terraform Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: ./terraform/environments/${{ github.event.inputs.environment }}/tfplan
          retention-days: 1

  deploy:
    name: 🚀 Deploy EKS Cluster
    needs: [validate, plan]
    if: needs.plan.outputs.plan_exitcode == '2'
    environment: ${{ github.event.inputs.environment }}
    runs-on: ubuntu-latest
    outputs:
      cluster_endpoint: ${{ steps.output.outputs.cluster_endpoint }}
      cluster_name: ${{ steps.output.outputs.cluster_name }}
      deployment_status: ${{ steps.apply.outcome }}
      
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ vars.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: Download Terraform Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan
          path: ./terraform/environments/${{ github.event.inputs.environment }}

      - name: Terraform Init
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TF_STATE_BUCKET }}" \
            -backend-config="key=eks/${{ github.event.inputs.environment }}/${{ github.event.inputs.name }}/terraform.tfstate" \
            -backend-config="region=${{ vars.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ vars.TF_STATE_LOCK_TABLE }}" \
            -backend-config="encrypt=true"

      - name: Terraform Apply
        id: apply
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        env:
          TF_VAR_cluster_name: ${{ github.event.inputs.name }}
          TF_VAR_environment: ${{ github.event.inputs.environment }}
        run: |
          echo "🚀 Deploying EKS cluster..."
          terraform apply tfplan
          echo "✅ Terraform apply completed"

      - name: Get Terraform Outputs
        id: output
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          cluster_endpoint=$(terraform output -raw cluster_endpoint)
          cluster_name=$(terraform output -raw cluster_name)
          
          echo "cluster_endpoint=$cluster_endpoint" >> $GITHUB_OUTPUT
          echo "cluster_name=$cluster_name" >> $GITHUB_OUTPUT
          
          echo "📊 Cluster Details:"
          echo "   Name: $cluster_name"
          echo "   Endpoint: $cluster_endpoint"

  verify:
    name: ✅ Verify EKS Cluster
    needs: [validate, plan, deploy]
    if: needs.deploy.outputs.deployment_status == 'success'
    environment: ${{ github.event.inputs.environment }}
    runs-on: ubuntu-latest
    outputs:
      health_check_status: ${{ steps.health_check.outcome }}
      
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ vars.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v${{ env.KUBECTL_VERSION }}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl
        run: |
          echo "🔗 Configuring kubectl for cluster '${{ needs.deploy.outputs.cluster_name }}'..."
          aws eks update-kubeconfig \
            --region ${{ vars.AWS_REGION }} \
            --name ${{ needs.deploy.outputs.cluster_name }}

      - name: Wait for cluster to be ready
        timeout-minutes: 10
        run: |
          echo "⏳ Waiting for cluster to be ready..."
          for i in {1..30}; do
            if kubectl cluster-info >/dev/null 2>&1; then
              echo "✅ Cluster is responding"
              break
            fi
            echo "   Attempt $i/30: Cluster not ready yet, waiting 20 seconds..."
            sleep 20
          done

      - name: Health Check
        id: health_check
        timeout-minutes: 15
        run: |
          echo "🏥 Performing cluster health checks..."
          
          # Check cluster status
          echo "📊 Cluster Status:"
          kubectl cluster-info
          
          # Check nodes
          echo "🖥️ Node Status:"
          kubectl get nodes -o wide
          
          # Wait for nodes to be ready
          echo "⏳ Waiting for all nodes to be ready..."
          kubectl wait --for=condition=Ready nodes --all --timeout=600s
          
          # Check system pods
          echo "🏗️ System Pods Status:"
          kubectl get pods -n kube-system
          
          # Wait for system pods to be ready
          echo "⏳ Waiting for system pods to be ready..."
          kubectl wait --for=condition=Ready pods --all -n kube-system --timeout=300s
          
          # Verify we can create resources
          echo "🧪 Testing resource creation..."
          kubectl create namespace test-deployment --dry-run=client -o yaml | kubectl apply -f -
          kubectl delete namespace test-deployment
          
          echo "✅ All health checks passed!"

      - name: Cluster Information Summary
        run: |
          echo "🎉 EKS Cluster Successfully Deployed and Verified!"
          echo ""
          echo "📋 Cluster Details:"
          echo "   Name: ${{ needs.deploy.outputs.cluster_name }}"
          echo "   Environment: ${{ github.event.inputs.environment }}"
          echo "   Region: ${{ vars.AWS_REGION }}"
          echo "   Endpoint: ${{ needs.deploy.outputs.cluster_endpoint }}"
          echo ""
          echo "🔗 To connect to your cluster:"
          echo "   aws eks update-kubeconfig --region ${{ vars.AWS_REGION }} --name ${{ needs.deploy.outputs.cluster_name }}"
          echo ""
          echo "🛠️ Useful commands:"
          echo "   kubectl get nodes"
          echo "   kubectl get pods --all-namespaces"

  cleanup_on_failure:
    name: 🧹 Cleanup on Failure
    needs: [validate, plan, deploy, verify]
    if: |
      always() && 
      github.event.inputs.destroy_on_failure == 'true' && 
      (needs.deploy.outputs.deployment_status == 'failure' || 
       needs.verify.outputs.health_check_status == 'failure')
    environment: ${{ github.event.inputs.environment }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ vars.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TF_STATE_BUCKET }}" \
            -backend-config="key=eks/${{ github.event.inputs.environment }}/${{ github.event.inputs.name }}/terraform.tfstate" \
            -backend-config="region=${{ vars.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ vars.TF_STATE_LOCK_TABLE }}" \
            -backend-config="encrypt=true"

      - name: Terraform Destroy
        working-directory: ./terraform/environments/${{ github.event.inputs.environment }}
        env:
          TF_VAR_cluster_name: ${{ github.event.inputs.name }}
          TF_VAR_environment: ${{ github.event.inputs.environment }}
        run: |
          echo "🧹 Destroying failed deployment..."
          terraform destroy \
            -var-file="terraform.tfvars" \
            -auto-approve
          echo "✅ Cleanup completed"

      - name: Cleanup Summary
        run: |
          echo "🧹 Cleanup completed due to deployment failure"
          echo "💡 You can disable automatic cleanup by setting 'destroy_on_failure' to false"

  notify_completion:
    name: 📢 Deployment Summary
    needs: [validate, plan, deploy, verify, cleanup_on_failure]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
      - name: Deployment Summary
        run: |
          echo "📊 EKS Deployment Summary"
          echo "========================"
          echo "Cluster Name: ${{ github.event.inputs.name }}"
          echo "Environment: ${{ github.event.inputs.environment }}"
          echo "Region: ${{ vars.AWS_REGION }}"
          echo ""
          
          if [[ "${{ needs.verify.outputs.health_check_status }}" == "success" ]]; then
            echo "✅ Status: SUCCESSFUL"
            echo "🎉 Your EKS cluster is ready to use!"
          elif [[ "${{ needs.cleanup_on_failure.result }}" == "success" ]]; then
            echo "❌ Status: FAILED (Resources cleaned up)"
            echo "💡 Check the logs above for failure details"
          elif [[ "${{ needs.deploy.outputs.deployment_status }}" == "failure" ]]; then
            echo "❌ Status: DEPLOYMENT FAILED"
            echo "⚠️  Some resources may still exist - manual cleanup might be needed"
          else
            echo "⚠️ Status: INCOMPLETE"
            echo "🔍 Check individual job statuses for details"
          fi